version: "3"
services:
  hadoop:
    build: ./hadoop
    image: "hadoop:python3"
    container_name: "hadoop"
    networks:
      hadoop_cluster:
        ipv4_address: "192.168.11.2"
    ports:
      - "8020:8020"
      - "8042:8042"
      - "8088:8088" 
      - "9000:9000"
      - "19888:19888" 
      - "50070:50070" 
      - "50075:50075"  
    # stdin_open: true
    # tty: true
  jupyter:
    build: 
      context: https://github.com/jupyter/docker-stacks.git#0f2a7473c41f2c865e836d70f8ff8c9c7b7ed28c:pyspark-notebook
      args:
      - spark_version=3.1.1
      - hadoop_version=2.7
      - spark_checksum=5C773553B785B16237DFBE7A39F34BEA6BF1D4E10E520BD27D55B2767E2883DE5A06ACF33447E571570A2D3CC34B5094F15D17BEF81A2AB16080A64F3AB34A0B
      - openjdk_version=8 
      - py4j_version=0.10.9
    image: "pyspark-notebook:spark-3.1.1"
    container_name: "notebook"
    environment:
      - HADOOP_CONF_DIR=/home/jovyan/hadoop-configs/
      - DOCKER_BUILDKIT=0
    ports:
      - "8888:8888"
    volumes:
       - "/Users/sturm/Development/python/ds_bd_ss20/ds_bd:/home/jovyan/work"  
       - "/Users/sturm/Development/python/ds_bd_ss20/ds_bd/hadoop-configs:/home/jovyan/hadoop-configs"
       - "/Users/sturm/Development/jupyter_with_yarn/pyspark-notebook/before-notebook:/usr/local/bin/before-notebook.d/"
    networks:
      hadoop_cluster:
        ipv4_address: "192.168.11.3"   
networks:
  hadoop_cluster:
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet:  192.168.11.0/24